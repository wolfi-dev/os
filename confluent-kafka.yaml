package:
  name: confluent-kafka
  # Upstream versioning is too weird that we need to work-around it.
  # Release Monitor returns the latest version as `7.7.0-314-ccs` format:
  # https://release-monitoring.org/api/v2/versions/?project_id=371656
  # In order to make the `update:` section happy:
  # 1. We need to transform it by replacing the last `-` with `.` to match
  # with the `version:` field.
  # 2. Created a new variable `mangled-package-version` to append `-ccs` to the
  # version.
  version: "8.0.0.370"
  epoch: 0
  description: Community edition of Confluent Kafka.
  copyright:
    - license: Apache-2.0
  dependencies:
    runtime:
      - bash # Required by kafka - uses shebangs to launch the image.
      - busybox
      - confluent-common-docker
      - confluent-common-docker-base
      - confluent-common-docker-ub
      - confluent-docker-utils
      - confluent-kafka-images-kafka
      - openjdk-17-default-jvm
      - openjdk-17-jre

environment:
  contents:
    packages:
      - busybox
      - ca-certificates-bundle
      - curl
      - gradle
      - openjdk-17
      - sbt
  environment:
    JAVA_HOME: /usr/lib/jvm/java-17-openjdk

var-transforms:
  - from: ${{package.version}}
    match: ^(.+)\.(\d+)$
    replace: $1-$2-ccs
    to: mangled-package-version

pipeline:
  - uses: git-checkout
    with:
      expected-commit: 594616115855a040525ba8396cc2e982beb08e9a
      repository: https://github.com/confluentinc/kafka
      tag: v${{vars.mangled-package-version}}

  - runs: |
      export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8

      gradle clean releaseTarGz

      nohup /usr/lib/kafka/bin/zookeeper-server-start.sh /usr/lib/kafka/config/zookeeper.properties > ${{targets.destdir}}/usr/lib/kafka/logs/zookeeper.out 2> zookeeper.err < /dev/null &
      tar -xzvf core/build/distributions/kafka_*-${{vars.mangled-package-version}}.tgz

      mkdir -p ${{targets.destdir}}/usr/lib/kafka/logs
      mkdir -p ${{targets.destdir}}/etc/kafka
      mkdir -p ${{targets.destdir}}/var/lib/kafka/data

      mv kafka_*-${{vars.mangled-package-version}}/bin ${{targets.destdir}}/usr/lib/kafka
      mv kafka_*-${{vars.mangled-package-version}}/libs ${{targets.destdir}}/usr/lib/kafka
      mv kafka_*-${{vars.mangled-package-version}}/config ${{targets.destdir}}/usr/lib/kafka

      # Install required runtime scripts
      mkdir -p ${{targets.destdir}}/usr/bin
      for file in $(find ./bin -type f -exec grep -lE '^#!(/usr/bin/env |/bin/)' {} \;); do
        filename=$(basename "$f")
        install -D -m755 "$file" ${{targets.destdir}}/usr/bin/"$filename"
      done

      # Create a symlink for the kafka libs since upstream images expect it to be in /usr/share/java/kafka:
      # https://github.com/confluentinc/kafka/blob/b66558da5d6b33c2fba9f424131575b948e6f611/bin/kafka-run-class.sh#L197
      mkdir -p ${{targets.destdir}}/usr/share/java/kafka
      # ln -sf /usr/lib/kafka/libs/* ${{targets.destdir}}/usr/share/java/kafka/

      # symlink every file in /usr/lib/kafka/libs to /usr/share/java/kafka
      for file in "${{targets.destdir}}"/usr/lib/kafka/libs/*; do
        ln -sf /usr/lib/kafka/libs/$(basename $file) ${{targets.destdir}}/usr/share/java/kafka/$(basename $file)
      done

      # /etc/confluent/docker/ensure runs kafka-storage whereas upstream only provides kafka-storage.sh for some reason.
      echo "#!/usr/bin/env bash" > ${{targets.destdir}}/usr/bin/kafka-storage
      echo "exec \"\$0.sh\" \"\$@\"" >> ${{targets.destdir}}/usr/bin/kafka-storage
      chmod +x ${{targets.destdir}}/usr/bin/kafka-storage

      # Clean up windows
      rm -rf ${{targets.destdir}}/usr/lib/kafka/bin/*.bat

# Need to use Git poller as confluent blocks GitHub API requests from GH runners
update:
  enabled: true
  schedule:
    period: daily
    reason: Confluent Kafka cut a high number of tags every day.
  git:
    strip-prefix: v
    strip-suffix: -ccs
  ignore-regex-patterns:
    - -rc.*
  version-transform:
    - match: ^(\d+\.\d+\.\d+)\-(\d+)$
      replace: $1.$2

test:
  environment:
    contents:
      packages:
        - bash
        - openjdk-17-default-jvm
        - procps
        - curl
    environment:
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
      KAFKA_LOG_DIRS: "/tmp/kafka-logs"
      KAFKA_LOG4J_OPTS: "-Dlog4j2.configurationFile=file:/usr/lib/kafka/config/tools-log4j2.yaml"
  pipeline:
    # AUTOGENERATED
    - runs: |
        kafka-acls --version
        kafka-acls.sh --version
        kafka-broker-api-versions --version
        kafka-broker-api-versions.sh --version
        kafka-client-metrics.sh --version
        kafka-configs --version
        kafka-configs.sh --version
        kafka-console-consumer --version
        kafka-console-consumer.sh --version
        kafka-console-producer --version
        kafka-console-producer.sh --version
        kafka-console-share-consumer.sh --version
        kafka-consumer-groups --version
        kafka-consumer-groups.sh --version
        kafka-consumer-perf-test --version
        kafka-consumer-perf-test.sh --version
        kafka-delegation-tokens --version
        kafka-delegation-tokens.sh --version
        kafka-delete-records --version
        kafka-delete-records.sh --version
        kafka-dump-log.sh --version
        kafka-get-offsets.sh --version
        kafka-jmx.sh --version
        kafka-leader-election.sh --version
        kafka-log-dirs --version
        kafka-log-dirs.sh --version
        kafka-metadata-quorum.sh --help
        kafka-reassign-partitions --version
        kafka-reassign-partitions.sh --version
        kafka-replica-verification --version
        kafka-replica-verification.sh --version
        kafka-run-class --version
        kafka-run-class.sh --version
        kafka-server-start --version
        kafka-server-start.sh --version
        kafka-share-groups.sh --version
        kafka-storage --help
        kafka-storage.sh --help
        kafka-streams-application-reset --version
        kafka-streams-application-reset.sh --version
        kafka-topics --version
    - name: "Initialize Kafka storage"
      runs: |
        mkdir -p /tmp/kafka-logs
        CLUSTER_ID="$(kafka-storage.sh random-uuid)"
        echo "Using cluster ID: $CLUSTER_ID"

        kafka-storage.sh format -t "$CLUSTER_ID" -c /usr/lib/kafka/config/server.properties --standalone
    - name: "Run integration test against Kafka server (KRaft mode)"
      runs: |
        nohup kafka-server-start.sh /usr/lib/kafka/config/server.properties > /tmp/kafka.log 2>&1 &
        sleep 10
        pgrep -f "kafka\.Kafka"

        # Create and verify test topic
        kafka-topics.sh --create --topic test-topic --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092
        kafka-topics.sh --describe --topic test-topic --bootstrap-server localhost:9092 | grep "test-topic"

        # Test message production and consumption
        echo "test message" | kafka-console-producer.sh --topic test-topic --bootstrap-server localhost:9092
        kafka-console-consumer.sh --topic test-topic --from-beginning --bootstrap-server localhost:9092 --max-messages 1 --timeout-ms 5000 | grep -q "test message"

        # Test Kafka configuration tools
        # Test broker configs
        kafka-configs.sh --bootstrap-server localhost:9092 --describe --entity-type brokers --entity-default

        # Test topic configs
        kafka-configs.sh --bootstrap-server localhost:9092 --describe --entity-type topics --entity-name test-topic
