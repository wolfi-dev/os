package:
  name: kubeflow-pipelines-visualization-server
  version: 2.2.0
  epoch: 0
  description: Machine Learning Pipelines for Kubeflow
  copyright:
    - license: Apache-2.0
  target-architecture:
    - x86_64 # Since tensorflow-data-validation is not available for aaarch64 yet
  dependencies:
    runtime:
      - py3.10-google-cloud-sdk
      - python-3.10

environment:
  contents:
    packages:
      - build-base
      - busybox
      - ca-certificates-bundle
      - py3.10-crcmod
      - py3.10-pip
      - python-3.10
      - python-3.10-dev

pipeline:
  - uses: git-checkout
    with:
      repository: https://github.com/kubeflow/pipelines
      tag: ${{package.version}}
      expected-commit: dd59f48cdd0f6cd7fac40306277ef5f3dad6e263

  - uses: patch
    with:
      patches: 0001-Bump-dependencies.patch

  - runs: |
      ln -sf /usr/bin/python3.10 /usr/bin/python3
      mkdir -p ${{targets.destdir}}/usr/share/app
      cp -r backend/src/apiserver/visualization/* ${{targets.destdir}}/usr/share/app/
      cd ${{targets.destdir}}/usr/share/app/

      sed -i 's/tensorflow==/#tensorflow==/g' requirements.txt

      pip install --root=${{targets.destdir}} --prefix=/usr -r requirements.txt
      find ${{targets.destdir}} -name "*.pyc" -exec rm -rf '{}' +

      # "collections" is deprecated in Python 3.10, use "collections.abc" instead
      sed -i 's/collections/collections.abc/g' ${{targets.destdir}}/usr/lib/python3.10/site-packages/gcsfs/mapping.py

      # CVE-2023-47248, GHSA-5wvp-7f3h-6wmm
      pip install pyarrow-hotfix
      sed -i '1 i\import pyarrow_hotfix' server.py

  - uses: strip

update:
  enabled: true
  ignore-regex-patterns:
    - "sdk-"
  github:
    identifier: kubeflow/pipelines

test:
  environment:
    contents:
      packages:
        - wolfi-base
        - curl
        - bash
  pipeline:
    - runs: |
        #!/bin/bash
        set -x

        # start the server
        export HOME=/usr/share/app
        cd $HOME
        /usr/bin/python server.py &
        sleep 5

        # simulate the upstream unit test suite: https://github.com/kubeflow/pipelines/blob/master/backend/src/apiserver/visualization/test_server.py

        BASE_URL="http://localhost:8888"

        # Function to print error message and exit on failure
        exit_on_failure() {
          echo "$1" # Print error message
          exit 1    # Exit with error status
        }

        # Function to perform a curl request and check the expected status
        do_test() {
          local url=$1
          local method=$2
          local data=$3
          local expected_status=$4

          if [ "$method" = "POST" ]; then
            response=$(curl -s -o /dev/null -w "%{http_code}" -X POST "$url" --data "$data")
          else
            response=$(curl -s -o /dev/null -w "%{http_code}" -X GET "$url")
          fi

          if [ "$response" != "$expected_status" ]; then
            exit_on_failure "Test failed at $url. Expected HTTP status $expected_status, got $response."
          fi
        }

        # Test: healthcheck
        do_test "${BASE_URL}/" "GET" "" "200"

        # Test: create_visualization_fails_when_nothing_is_provided
        do_test "${BASE_URL}/" "POST" "" "400"

        # Test: create_visualization_fails_when_missing_type
        do_test "${BASE_URL}/" "POST" "source=gs://ml-pipeline/data.csv" "400"

        # Test: create_visualization_fails_when_missing_source
        do_test "${BASE_URL}/" "POST" "type=test" "400"

        # Test: create_visualization_passes_when_missing_source_and_type_is_custom
        do_test "${BASE_URL}/" "POST" "type=custom" "200"

        # Test: create_visualization_fails_when_invalid_json_is_provided
        do_test "${BASE_URL}/" "POST" "type=test&source=gs://ml-pipeline/data.csv&arguments={" "400"

        # Test: create_visualization
        do_test "${BASE_URL}/" "POST" "type=test&source=gs://ml-pipeline/data.csv" "200"

        echo "All tests passed."
