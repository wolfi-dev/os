package:
  name: ollama
  version: "0.7.0"
  epoch: 0
  description: Get up and running with Llama 2 and other large language models locally
  copyright:
    - license: MIT

pipeline:
  - uses: git-checkout
    with:
      repository: https://github.com/ollama/ollama
      tag: v${{package.version}}
      expected-commit: bd68d3ae50c67ba46ee94a584fa6d0386e4b8522

  - uses: go/build
    with:
      modroot: .
      packages: .
      output: ollama
      ldflags: -X=github.com/ollama/ollama/version.Version=${{package.version}} -linkmode external -extldflags "-static"

  - uses: strip

update:
  enabled: true
  github:
    identifier: ollama/ollama
    strip-prefix: v

test:
  environment:
    contents:
      packages:
        - curl
  pipeline:
    - name: Ensure CLI works
      runs: |
        ollama --version | grep "${{package.version}}"
        ollama --help | grep "Large language model"
    - name: Test if Ollama server works
      runs: |
        HOST_IP=localhost
        PREDEFINED_PORT=9999
        OLLAMA_HOST=$HOST_IP:$PREDEFINED_PORT ollama serve &
        SERVER_PID=$!
        sleep 5

        # Check if the server is running
        curl -s $HOST_IP:$PREDEFINED_PORT | grep -q "Ollama is running"

        # Kill the server process
        kill $SERVER_PID
