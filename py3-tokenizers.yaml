package:
  name: py3-tokenizers
  version: "0.22.2"
  epoch: 0
  description: Fast State-of-the-Art Tokenizers optimized for Research and Production
  copyright:
    - license: Apache-2.0
  dependencies:
    provider-priority: 0

vars:
  pypi-package: tokenizers
  module-name: tokenizers

data:
  - name: py-versions
    items:
      3.10: '310'
      3.11: '311'
      3.12: '312'
      3.13: '313'

environment:
  contents:
    packages:
      - build-base
      - busybox
      - maturin
      - py3-supported-maturin
      - py3-supported-pip
      - py3-supported-setuptools-rust
      - rust
      - wolfi-base

pipeline:
  - uses: git-checkout
    with:
      repository: https://github.com/huggingface/tokenizers
      tag: v${{package.version}}
      expected-commit: 6573f2c56172bac56f211e77934be3215adef2c2

subpackages:
  - range: py-versions
    name: py${{range.key}}-${{vars.pypi-package}}
    description: ${{vars.pypi-package}} installed for python${{range.key}}
    dependencies:
      runtime:
        - py${{range.key}}-huggingface-hub
      provides:
        - py3-${{vars.pypi-package}}
      provider-priority: ${{range.value}}
    pipeline:
      - working-directory: bindings/python
        uses: py/pip-build-install
        with:
          python: python${{range.key}}
    test:
      pipeline:
        - uses: python/import
          with:
            python: python${{range.key}}
            import: ${{vars.module-name}}
        - name: verify installation
          runs: |
            echo "
            from tokenizers import Tokenizer
            from tokenizers.models import BPE
            from tokenizers.trainers import BpeTrainer
            from tokenizers.pre_tokenizers import Whitespace

            tokenizer = Tokenizer(BPE())

            tokenizer.pre_tokenizer = Whitespace()

            trainer = BpeTrainer(vocab_size=5000, min_frequency=2)
            tokenizer.train_from_iterator([\"Hello, world! This is a test sentence.\", \"Another example sentence.\"], trainer)

            output = tokenizer.encode(\"Hello, world! This is a test sentence.\")
            print(\"Encoded tokens:\", output.ids)
            print(\"Decoded text:\", tokenizer.decode(output.ids))
            " | python${{range.key}}
        - uses: test/tw/ldd-check
        - uses: test/tw/pip-check

  - name: py3-supported-${{vars.pypi-package}}
    description: meta package providing ${{vars.pypi-package}} for supported python versions.
    dependencies:
      runtime:
        - py3.10-${{vars.pypi-package}}
        - py3.11-${{vars.pypi-package}}
        - py3.12-${{vars.pypi-package}}
        - py3.13-${{vars.pypi-package}}
    test:
      pipeline:
        - uses: test/tw/metapackage

test:
  pipeline:
    - uses: test/tw/byproductpackage

update:
  enabled: true
  git:
    strip-prefix: v
  ignore-regex-patterns:
    - ^python-v.*
    - ^node-v.*
    - ^rust-v.*
