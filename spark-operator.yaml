package:
  name: spark-operator
  version: "2.4.0"
  epoch: 2 # CVE-2025-61729
  description: Kubernetes operator for managing the lifecycle of Apache Spark applications on Kubernetes.
  copyright:
    - license: Apache-2.0
  dependencies:
    runtime:
      - procps

pipeline:
  - uses: git-checkout
    with:
      repository: https://github.com/kubeflow/spark-operator
      tag: v${{package.version}}
      expected-commit: 1199997006678a6d520c0755a0d543b3c1c47649

  - uses: go/build
    with:
      packages: ./cmd/operator
      output: spark-operator
      ldflags: |
        -X github.com/kubeflow/spark-operator/v2.version=$(cat VERSION | sed "s/^v//")
        -X github.com/kubeflow/spark-operator/v2.buildDate=$(date -u -d "@$SOURCE_DATE_EPOCH" +"%Y-%m-%dT%H:%M:%S%:z")
        -X github.com/kubeflow/spark-operator/v2.gitCommit=$(git rev-parse HEAD)
        -X github.com/kubeflow/spark-operator/v2.gitTreeState=$(if [ -z "`git status --porcelain`" ]; then git describe --exact-match --tags HEAD 2>/dev/null; fi)

  - uses: strip

subpackages:
  - name: spark-operator-oci-entrypoint
    pipeline:
      - runs: |
          mkdir -p ${{targets.subpkgdir}}/usr/bin/
          cp entrypoint.sh ${{targets.subpkgdir}}/usr/bin/
          chmod 0755 ${{targets.subpkgdir}}/usr/bin/entrypoint.sh
    dependencies:
      runtime:
        - openssl
        - tini
        - posix-libc-utils
        - coreutils
    test:
      pipeline:
        - runs: |
            set -x
            stat /usr/bin/entrypoint.sh
            test -x /usr/bin/entrypoint.sh

update:
  enabled: true
  github:
    identifier: kubeflow/spark-operator
    strip-prefix: v
    use-tag: true
  ignore-regex-patterns:
    - ^spark-operator-chart-.*

test:
  environment:
    contents:
      packages:
        - curl
  pipeline:
    - runs: |
        spark-operator version | grep ${{package.version}}
        spark-operator --help
    - uses: test/kwok/cluster
      with:
        serviceaccount: true
    - name: Launch operator with kwok cluster
      uses: test/daemon-check-output
      with:
        setup: |
          kubectl config view --minify --raw > /tmp/kubeconfig.yaml
          kubectl apply -f https://raw.githubusercontent.com/kubeflow/spark-operator/refs/tags/v${{package.version}}/charts/spark-operator-chart/crds/sparkoperator.k8s.io_sparkconnects.yaml
          kubectl apply --server-side=true -f https://raw.githubusercontent.com/kubeflow/spark-operator/refs/tags/v${{package.version}}/charts/spark-operator-chart/crds/sparkoperator.k8s.io_sparkapplications.yaml
          kubectl apply --server-side=true -f https://raw.githubusercontent.com/kubeflow/spark-operator/refs/tags/v${{package.version}}/charts/spark-operator-chart/crds/sparkoperator.k8s.io_scheduledsparkapplications.yaml
          sleep 1
        start: spark-operator controller start --metrics-bind-address ":8080" --health-probe-bind-address ":8081"
        timeout: 30
        expected_output: |
          Starting Controller
          Starting workers
        post: |
          curl --silent --fail localhost:8080/metrics
          curl --silent --fail localhost:8081/healthz
    - name: Launch webhook with kwok cluster
      uses: test/daemon-check-output
      with:
        setup: |
          kubectl create ns spark-operator
        start: spark-operator webhook start --metrics-bind-address ":8080" --health-probe-bind-address ":8081"
        timeout: 30
        expected_output: |
          Starting webhook server
          Starting Controller
          Starting workers
        post: |
          curl --silent --fail localhost:8080/metrics
          curl --silent --fail localhost:8081/healthz
